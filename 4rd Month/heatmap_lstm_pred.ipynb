{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a3830ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dossiers cr√©√©s : cartes_climat2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import folium\n",
    "import geopandas as gpd\n",
    "import branca.colormap as cm\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from cartiflette import carti_download\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Cr√©ation de l'arborescence pour le projet LSTM\n",
    "folders = [\"cartes_climat2/historique\", \"cartes_climat2/predictions_2008\"]\n",
    "for folder in folders:\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "print(\"‚úÖ Dossiers cr√©√©s : cartes_climat2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ad4d81be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è≥ T√©l√©chargement des fronti√®res administratives...\n",
      "‚úÖ Donn√©es g√©ographiques t√©l√©charg√©es.\n",
      "‚úÖ Points filtr√©s en Auvergne : 90300 lignes.\n"
     ]
    }
   ],
   "source": [
    "# 1. Chargement des donn√©es m√©t√©o (assurez-vous que df_raw est bien charg√© en Cellule 0/1)\n",
    "df_raw = pd.read_csv(\"df_clean.csv\", index_col=0)\n",
    "df_raw.index = pd.to_datetime(df_raw.index)\n",
    "df_raw = df_raw.sort_values(['latitude', 'longitude', 'time'])\n",
    "\n",
    "# 2. T√©l√©chargement des contours des d√©partements (URL stable GitHub)\n",
    "print(\"‚è≥ T√©l√©chargement des fronti√®res administratives...\")\n",
    "# Cette URL est tr√®s stable et contient les codes (01, 02, 03...) au format texte\n",
    "url_geojson = \"https://raw.githubusercontent.com/gregoiredavid/france-geojson/master/departements.geojson\"\n",
    "\n",
    "try:\n",
    "    # Lecture directe depuis GitHub\n",
    "    departements_fr = gpd.read_file(url_geojson)\n",
    "    print(\"‚úÖ Donn√©es g√©ographiques t√©l√©charg√©es.\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erreur lors du t√©l√©chargement : {e}\")\n",
    "\n",
    "# 3. Filtrage Auvergne (03=Allier, 15=Cantal, 43=H-Loire, 63=P-de-D√¥me)\n",
    "# Attention : Dans ce fichier, la colonne s'appelle 'code' et non 'INSEE_DEP'\n",
    "deps_codes = ['03', '15', '43', '63']\n",
    "auvergne_deps = departements_fr[departements_fr['code'].isin(deps_codes)].copy()\n",
    "\n",
    "# 4. Filtrage spatial des points m√©t√©o\n",
    "gdf_total = gpd.GeoDataFrame(\n",
    "    df_raw, \n",
    "    geometry=gpd.points_from_xy(df_raw['longitude'], df_raw['latitude']),\n",
    "    crs=\"EPSG:4326\"\n",
    ")\n",
    "\n",
    "# Jointure spatiale pour ne garder que les points √† l'int√©rieur de l'Auvergne\n",
    "gdf_auvergne = gpd.sjoin(gdf_total, auvergne_deps[['code', 'geometry']], predicate=\"within\")\n",
    "\n",
    "# Tri indispensable pour la logique de s√©rie temporelle (LSTM)\n",
    "gdf_auvergne = gdf_auvergne.sort_values(['latitude', 'longitude', 'time'])\n",
    "print(f\"‚úÖ Points filtr√©s en Auvergne : {gdf_auvergne.shape[0]} lignes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9b5ee441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Features\n",
    "gdf_auvergne['month'] = gdf_auvergne.index.month\n",
    "gdf_auvergne['month_sin'] = np.sin(2 * np.pi * gdf_auvergne['month'] / 12)\n",
    "gdf_auvergne['month_cos'] = np.cos(2 * np.pi * gdf_auvergne['month'] / 12)\n",
    "\n",
    "# 2. Scalers\n",
    "scaler_skt = StandardScaler()\n",
    "scaler_geo = StandardScaler()\n",
    "\n",
    "# S√©paration temporelle\n",
    "df_train_full = gdf_auvergne[gdf_auvergne.index.year <= 2007].copy()\n",
    "df_test_full = gdf_auvergne[gdf_auvergne.index.year >= 2007].copy() # On garde 2007 pour le \"lookback\"\n",
    "\n",
    "df_train_full['skt_norm'] = scaler_skt.fit_transform(df_train_full[['skt']])\n",
    "df_train_full[['lat_norm', 'lon_norm']] = scaler_geo.fit_transform(df_train_full[['latitude', 'longitude']])\n",
    "\n",
    "df_test_full['skt_norm'] = scaler_skt.transform(df_test_full[['skt']])\n",
    "df_test_full[['lat_norm', 'lon_norm']] = scaler_geo.transform(df_test_full[['latitude', 'longitude']])\n",
    "\n",
    "features_list = ['skt_norm', 'month_sin', 'month_cos', 'lat_norm', 'lon_norm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "303d2236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Entra√Ænement du LSTM Spatial...\n",
      "Epoch 1/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.2461\n",
      "Epoch 2/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0812\n",
      "Epoch 3/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0753\n",
      "Epoch 4/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0724\n",
      "Epoch 5/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0703\n",
      "Epoch 6/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0682\n",
      "Epoch 7/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0664\n",
      "Epoch 8/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0642\n",
      "Epoch 9/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0617\n",
      "Epoch 10/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0580\n",
      "Epoch 11/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0531\n",
      "Epoch 12/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0492\n",
      "Epoch 13/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0452\n",
      "Epoch 14/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0416\n",
      "Epoch 15/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0391\n",
      "Epoch 16/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0353\n",
      "Epoch 17/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0320\n",
      "Epoch 18/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0290\n",
      "Epoch 19/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0261\n",
      "Epoch 20/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0231\n",
      "Epoch 21/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0203\n",
      "Epoch 22/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0165\n",
      "Epoch 23/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0141\n",
      "Epoch 24/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0124\n",
      "Epoch 25/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0105\n",
      "Epoch 26/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0095\n",
      "Epoch 27/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0084\n",
      "Epoch 28/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0077\n",
      "Epoch 29/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0066\n",
      "Epoch 30/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0065\n",
      "Epoch 31/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0057\n",
      "Epoch 32/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0053\n",
      "Epoch 33/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0051\n",
      "Epoch 34/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0048\n",
      "Epoch 35/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0044\n",
      "Epoch 36/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0043\n",
      "Epoch 37/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0040\n",
      "Epoch 38/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0039\n",
      "Epoch 39/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0037\n",
      "Epoch 40/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0035\n",
      "Epoch 41/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0035\n",
      "Epoch 42/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0034\n",
      "Epoch 43/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0032\n",
      "Epoch 44/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0031\n",
      "Epoch 45/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0031\n",
      "Epoch 46/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0029\n",
      "Epoch 47/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0028\n",
      "Epoch 48/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0028\n",
      "Epoch 49/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0028\n",
      "Epoch 50/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0026\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n"
     ]
    }
   ],
   "source": [
    "WINDOW_SIZE = 12 \n",
    "\n",
    "def create_lstm_sequences(df, window, is_test=False):\n",
    "    X, y, info = [], [], []\n",
    "    for (lat, lon), group in df.groupby(['latitude', 'longitude']):\n",
    "        values = group[features_list].values\n",
    "        if len(values) > window:\n",
    "            for i in range(len(values) - window):\n",
    "                target_date = group.index[i + window]\n",
    "                if is_test and target_date.year != 2008: continue\n",
    "                X.append(values[i : i + window, :])\n",
    "                y.append(values[i + window, 0])\n",
    "                info.append([target_date, lat, lon])\n",
    "    return np.array(X), np.array(y), info\n",
    "\n",
    "X_train, y_train, _ = create_lstm_sequences(df_train_full, WINDOW_SIZE)\n",
    "X_test, y_test, info_test = create_lstm_sequences(df_test_full, WINDOW_SIZE, is_test=True)\n",
    "\n",
    "# Architecture LSTM\n",
    "model = Sequential([\n",
    "    Input(shape=(WINDOW_SIZE, len(features_list))),\n",
    "    LSTM(64, return_sequences=True, activation='tanh'),\n",
    "    Dropout(0.2),\n",
    "    LSTM(32, activation='tanh'),\n",
    "    Dense(1)\n",
    "])\n",
    "model.compile(optimizer=Adam(0.001), loss='mse')\n",
    "\n",
    "print(\"üöÄ Entra√Ænement du LSTM Spatial...\")\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=256)\n",
    "\n",
    "# Pr√©diction\n",
    "y_pred_norm = model.predict(X_test)\n",
    "df_2008_lstm = pd.DataFrame(info_test, columns=['time', 'latitude', 'longitude'])\n",
    "df_2008_lstm['skt'] = scaler_skt.inverse_transform(y_test.reshape(-1, 1))\n",
    "df_2008_lstm['pred_lstm'] = scaler_skt.inverse_transform(y_pred_norm)\n",
    "df_2008_lstm.set_index('time', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c282327e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_pro_map(data, date_label, col_name, output_path, title_text):\n",
    "    # 1. Fond de carte clair\n",
    "    m = folium.Map(location=[45.7, 3.2], zoom_start=8, tiles=\"CartoDB positron\")\n",
    "    \n",
    "    # 2. CONVERSION DES BORNES POUR L'√âCHELLE (Kelvin -> Celsius)\n",
    "    # On calcule le min et max en Celsius pour que la l√©gende affiche -5, 10, 20...\n",
    "    vmin_c = data[col_name].min() - 273.15\n",
    "    vmax_c = data[col_name].max() - 273.15\n",
    "    \n",
    "    # Palette Bleu (Froid) -> Jaune -> Rouge (Chaud)\n",
    "    colors = cm.linear.RdYlBu_11.colors[::-1]\n",
    "    colormap = cm.LinearColormap(colors=colors, vmin=vmin_c, vmax=vmax_c)\n",
    "    colormap.caption = \"Temp√©rature (¬∞C)\"\n",
    "    colormap.add_to(m)\n",
    "\n",
    "    # 3. √âchantillonnage pour la clart√©\n",
    "    sampled = data.iloc[::2]\n",
    "\n",
    "    # 4. Contours des d√©partements\n",
    "    folium.GeoJson(auvergne_deps, style_function=lambda x: {\n",
    "        'fillColor': 'none', 'color': '#333', 'weight': 1.5, 'opacity': 0.4\n",
    "    }).add_to(m)\n",
    "\n",
    "    # 5. Dessin des points avec conversion individuelle pour le popup et la couleur\n",
    "    for _, row in sampled.iterrows():\n",
    "        val_k = row[col_name]\n",
    "        val_c = val_k - 273.15 # <--- CONVERSION R√âELLE ICI\n",
    "        \n",
    "        # On utilise la valeur Celsius pour obtenir la couleur sur l'√©chelle\n",
    "        color_point = colormap(val_c)\n",
    "        \n",
    "        popup_html = f\"\"\"\n",
    "        <div style=\"font-family: Arial; font-size: 12px; width: 160px;\">\n",
    "            <h4 style=\"margin:0; color:#333;\">{title_text}</h4>\n",
    "            <hr style=\"margin:5px 0;\">\n",
    "            <b>Mois :</b> {date_label}<br>\n",
    "            <b>Temp√©rature :</b> <b style=\"color:{color_point};\">{val_c:.2f} ¬∞C</b><br>\n",
    "            <b>Position :</b> {row['latitude']:.2f}, {row['longitude']:.2f}\n",
    "        </div>\n",
    "        \"\"\"\n",
    "        \n",
    "        folium.CircleMarker(\n",
    "            location=[row['latitude'], row['longitude']],\n",
    "            radius=5,\n",
    "            color=color_point,\n",
    "            fill=True,\n",
    "            fill_color=color_point,\n",
    "            fill_opacity=0.8,\n",
    "            stroke=True,\n",
    "            weight=0.8,\n",
    "            popup=folium.Popup(popup_html, max_width=250)\n",
    "        ).add_to(m)\n",
    "\n",
    "    # 6. Titre de la carte\n",
    "    title_html = f'''\n",
    "             <div style=\"position: fixed; top: 10px; left: 50px; width: 300px; z-index:9999; \n",
    "                         background-color: white; border:2px solid black; padding: 10px; border-radius:5px; opacity:0.9;\">\n",
    "                 <b>{title_text}</b><br>P√©riode : {date_label}\n",
    "             </div>\n",
    "             '''\n",
    "    m.get_root().html.add_child(folium.Element(title_html))\n",
    "    m.save(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0ef8c644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m113/113\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "‚úÖ df_results_lstm cr√©√© avec 3612 lignes.\n"
     ]
    }
   ],
   "source": [
    "# 1. Calcul des pr√©dictions sur les donn√©es de test\n",
    "y_pred_norm = model.predict(X_test)\n",
    "\n",
    "# 2. Inversion de la normalisation pour revenir aux vrais degr√©s Celsius\n",
    "y_pred_real = scaler_skt.inverse_transform(y_pred_norm).flatten()\n",
    "y_true_real = scaler_skt.inverse_transform(y_test.reshape(-1, 1)).flatten()\n",
    "\n",
    "# 3. CR√âATION DU DATAFRAME DE R√âSULTATS (C'est ici qu'on d√©finit le nom)\n",
    "df_results_lstm = pd.DataFrame(info_test, columns=['time', 'latitude', 'longitude'])\n",
    "df_results_lstm['skt'] = y_true_real\n",
    "df_results_lstm['pred_lstm'] = y_pred_real\n",
    "df_results_lstm.set_index('time', inplace=True)\n",
    "\n",
    "print(f\"‚úÖ df_results_lstm cr√©√© avec {len(df_results_lstm)} lignes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3d0ffc4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è≥ Pr√©paration et g√©n√©ration de l'Historique en Celsius...\n",
      "‚è≥ Pr√©paration et g√©n√©ration des Pr√©dictions LSTM en Celsius...\n",
      "‚ú® Termin√© ! Vos cartes en degr√©s Celsius sont pr√™tes dans 'cartes_climat2'.\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "# --- 1. PR√âPARATION DES DONN√âES HISTORIQUES (2000-2007) ---\n",
    "print(\"‚è≥ Pr√©paration et g√©n√©ration de l'Historique en Celsius...\")\n",
    "# On s'assure que la colonne 'period' existe √† partir de l'index temporel\n",
    "df_train_full['period'] = df_train_full.index.to_period('M')\n",
    "\n",
    "for period, group in df_train_full.groupby('period'):\n",
    "    # Moyenne spatiale mensuelle\n",
    "    monthly = group.groupby(['latitude', 'longitude'])[['skt']].mean().reset_index()\n",
    "    path_h = f\"cartes_climat2/historique/HIST_{period}.html\"\n",
    "    \n",
    "    generate_pro_map(\n",
    "        monthly, \n",
    "        str(period), \n",
    "        'skt', \n",
    "        path_h, \n",
    "        \"Historique Auvergne (¬∞C)\"\n",
    "    )\n",
    "\n",
    "# --- 2. PR√âPARATION DES PR√âDICTIONS LSTM (2008) ---\n",
    "print(\"‚è≥ Pr√©paration et g√©n√©ration des Pr√©dictions LSTM en Celsius...\")\n",
    "\n",
    "# On v√©rifie que les noms de colonnes correspondent √† vos r√©sultats LSTM\n",
    "# On applique le Z-score pour la propret√© (calcul√© sur 'skt')\n",
    "z_scores = np.abs(stats.zscore(df_results_lstm['skt']))\n",
    "df_2008_clean = df_results_lstm[z_scores < 3].copy()\n",
    "\n",
    "# On recr√©e la colonne 'period' ici aussi\n",
    "df_2008_clean['period'] = df_2008_clean.index.to_period('M')\n",
    "\n",
    "\n",
    "\n",
    "for p, group in df_2008_clean.groupby('period'):\n",
    "    # Moyenne par point pour le mois\n",
    "    monthly = group.groupby(['latitude', 'longitude'])[['skt', 'pred_lstm']].mean().reset_index()\n",
    "    \n",
    "    # Carte PR√âDITE (IA)\n",
    "    path_p = f\"cartes_climat2/predictions_2008/MAP_PRED_LSTM_{p}.html\"\n",
    "    generate_pro_map(monthly, str(p), 'pred_lstm', path_p, \"IA : Pr√©diction LSTM (¬∞C)\")\n",
    "    \n",
    "    # Carte R√âELLE (Contr√¥le)\n",
    "    path_r = f\"cartes_climat2/predictions_2008/MAP_REEL_{p}.html\"\n",
    "    generate_pro_map(monthly, str(p), 'skt', path_r, \"R√©alit√© : Terrain Auvergne (¬∞C)\")\n",
    "\n",
    "print(\"‚ú® Termin√© ! Vos cartes en degr√©s Celsius sont pr√™tes dans 'cartes_climat2'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a31056b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Transformers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
